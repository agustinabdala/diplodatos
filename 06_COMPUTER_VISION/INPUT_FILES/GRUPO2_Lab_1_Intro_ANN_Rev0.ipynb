{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT1WjbFzVFnB"
      },
      "source": [
        "# Breve introducción a ANN\n",
        "\n",
        "Tutorial basado en el artículo [Simple Introduction to Convolutional Neural Networks](https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac).\n",
        "\n",
        "Antes de comenzar con el alboratorio vamos a revisar los conceptos básicos de las *redes neuronales artificiales* (ANN por sus siglas en inglés) y como se aplican al procesamiento y análisis de imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPCMJYVcgzm-"
      },
      "source": [
        "## Motivación: análisis de imagen\n",
        "\n",
        "En las unidades anteriores hemos estado hablando básicamente de detectar características visuales en imágenes. Los investigadores desarrollaron múltiples técnicas de visión computacional para tratar estos problemas: SIFT, FAST, SURF, BRIEF, ORB, KAZE, etc. Sin embargo, en general estas técnicas presentaban dificultades para ciertos problemas: los detectores son demasiado simples o están diseñados para problemas muy específicos. \n",
        "\n",
        "Entonces la pregunta que surgió fue bastante obvia: ¿qué pasa si aprendemos las características visual que queremos detectar? Y la respuesta es simple: necesitamos un sistema que pueda hacer *aprendizaje de características* (o Feature Learning).\n",
        "\n",
        "El aprendizaje de características es una técnica que permite que un sistema encuentre automáticamente características relevantes para una tarea determinada, de manera que permite reemplazar el diseño manual de características. **Redes neuronales artificiales** es una de las técnicas que permite hacer esto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofOzmZziZ8sH"
      },
      "source": [
        "## Redes Neuronales artificiales\n",
        "\n",
        "Una **red neural artificial** es un modelo computacional que se inspira en la forma en como las redes neuronales biológicas del cerebro humano procesan la información. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpU2AKFzg3rZ"
      },
      "source": [
        "### Una sola neurona\n",
        "\n",
        "La unidad básica de cálculo en una red neuronal es la *neurona*, a menudo llamada nodo o unidad. Recibe información de algunos otros nodos, o de una fuente externa y calcula una salida. Cada entrada tiene un peso asociado (`w`), que se asigna en función de su importancia relativa a otras entradas. El nodo aplica una función `f` a la suma ponderada de sus entradas como se muestra a continuación:\n",
        "\n",
        "![](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-09-at-3-42-21-am.png?w=1136&h=606)\n",
        "\n",
        "La red anterior toma entradas numéricas `X1` y `X2` y tiene pesos `w1` y `w2` asociados con esas entradas. Además, hay otra entrada `1` con el peso `b` (llamado *bias*) asociado a ella, y por el momento vamos a omitir esta entrada.\n",
        "\n",
        "La salida `Y` de la neurona se calcula como se muestra en la figura. La función `f` se llama *función de activación*. Una función de activación toma un número y realiza una operación matemática determinada. Hay varias funciones de activación que se pueden encontrar en la práctica:\n",
        "\n",
        "* `Sigmoide`: toma una entrada de valor real y la aplasta para que oscile entre 0 y 1\n",
        "\n",
        "* `ReLU`: ReLU significa *unidad lineal rectificada*. Toma una entrada de valor real y la umbraliza a cero (reemplaza los valores negativos con cero)\n",
        "\n",
        "![](https://miro.medium.com/max/1742/1*XxxiA0jJvPrHEJHD4z893g.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "059yXzghgr6Z"
      },
      "source": [
        "### Red neuronal feedforward multicapa (MLP)\n",
        "\n",
        "La red neuronal feedforward fue el primer modelo ideado y a su vez el más simple. Contiene múltiples neuronas (nodos) dispuestas en capas. Los nodos de las capas adyacentes tienen conexiones entre ellos y todas estas conexiones tienen pesos asociados con ellas. Un ejemplo de una red neuronal feedforward se muestra en la figura:\n",
        "\n",
        "![](https://miro.medium.com/max/1200/1*BQ0SxdqC9Pl_3ZQtd3e45A.png)\n",
        "\n",
        "Una red neuronal feedforward (multilayer) consta de nodos en tres tipos de capas:\n",
        "\n",
        "1. *Capa de entrada*: los nodos de esta capa proporcionan información externa a la red. No se realiza ningún cálculo en estos nodo, simplemente transmiten la información a los nodos de la capa oculta.\n",
        "\n",
        "2. *Capas ocultas*: los nodos de estas capas realizan cálculos y transfieren información de los nodos de entrada a los nodos de salida. Una red feedforward puede tener cero o múltiples capas ocultas.\n",
        "\n",
        "3. *Capa de salida*: los nodos de salida son responsables de los cálculos y la transferencia de información de la red al mundo exterior.\n",
        "\n",
        "En una red feedforward, la información se mueve en una sola dirección, hacia adelante, desde los nodos de entrada, a través de los nodos ocultos y hacia los nodos de salida. No hay ciclos ni bucles en la red."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk9AyYeDiYLZ"
      },
      "source": [
        "### Entrenando una ANN: algoritmo Backpropagation\n",
        "\n",
        "El proceso por el cual una ANN aprende se conoce como algoritmo de *backpropagation*, o retropropagación (abreviado como *BackProp*):\n",
        "\n",
        "* Es un esquema de entrenamiento supervisado, lo que significa que aprende de datos de entrenamiento ya etiquetados.\n",
        "* En términos simples, BackProp consiste en \"aprender de los errores\". El algoritmo corrige el ANN cada vez que comete errores.\n",
        "* El objetivo del aprendizaje es asignar pesos correctos a las conexiones entre nodos de capas diferentes. Dado un vector de entrada, estos pesos determinan cuál es el vector de salida.\n",
        "\n",
        "#### Algoritmo BackProp\n",
        "\n",
        "![](https://miro.medium.com/max/600/0*zjTuE91Skw7y2Vx-)\n",
        "Fuente: https://gfycat.com/gifs/search/backpropagation\n",
        "\n",
        "\n",
        "Inicialmente, todos los pesos de borde se asignan aleatoriamente. Para cada entrada en el conjunto de datos de entrenamiento, el ANN se activa y se observa su salida. Esta salida se compara con la salida deseada que ya conocemos, y el error se *propaga* de nuevo a la capa anterior. Este error se observa y los pesos se *ajustan* en consecuencia. Este proceso se repite hasta que el error de salida esté por debajo de un umbral predeterminado.\n",
        "\n",
        "#### Predicción de nuevas entradas\n",
        "\n",
        "Una vez que termina el algoritmo BackProp, hemos aprendido una ANN, y está lista para trabajar con nuevas entradas. La siguiente figura muestra como fluye la información de una nueva entrada para una red que ya fue entrenada.\n",
        "\n",
        "![](https://miro.medium.com/max/1111/0*bmcR3nOLvyp1moa6.gif)\n",
        "\n",
        "Con el fin de mejorar el entendimiento de este proceso, se puede utilizar la web desarrollada por Adam Harley (http://scs.ryerson.ca/~aharley/vis/fc/) para visualizar en 3D una ANN que fue entrenada (usando Backpropagation) para reconocer dígitos escrito a mano sobre la base de datos MNIST.\n",
        "\n",
        "La red toma 784 valores numéricos de píxeles como entradas de una imagen de 28x28 de un dígito escrito a mano (tiene 784 nodos en la capa de entrada correspondientes a píxeles). La red tiene 300 nodos en la primera capa oculta, 100 nodos en la segunda capa oculta y 10 nodos en la capa de salida (correspondientes a los 10 dígitos)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtMBpJNcqWUE"
      },
      "source": [
        "## Problemas de las ANN tradicionales (MLP)\n",
        "\n",
        "Antes de empezar con la páctica de ANN para análisis de imágenes, vamos a repasar los problemas que presentan las ANN tradicionales.\n",
        "\n",
        "* Hay varios inconvenientes con las MLP, especialmente cuando se trata del procesamiento de imágenes. Los MLP usan un perceptrón para cada entrada (por ejemplo, píxel en una imagen, multiplicado por 3 en caso de RGB). La cantidad de pesos rápidamente se vuelve inmanejable para imágenes grandes. Para una imagen de 224x224 píxeles con 3 canales de color, hay alrededor de 150.000 pesos que deben entrenarse. Como resultado, surgen dificultades durante el entranamiento, como ser el *sobreajuste*.\n",
        "\n",
        "* Otro problema común es que los MLP reaccionan de manera diferente a una entrada (imágenes) y su versión desplazada: no son invariantes de traslación. Por ejemplo, si aparece una imagen de un gato en la parte superior izquierda de una imagen y otro en la parte inferior derecha de otra imagen, el MLP intentará corregirse y asumirá que siempre aparecerá un gato en esa sección de la imagen.\n",
        "\n",
        "Ahora si, ya podemos comenzar con la práctica de este laboratorio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "# Clasificación con ANN: predecir la clase de una imagen\n",
        "\n",
        "Tutorial extraído de https://www.tensorflow.org/tutorials/keras/classification\n",
        "\n",
        "En esta primera parte del laboratorio vamos entrenar una red neuronal para clasificar imagenes de ropa como ser zapatos, vestidos, camisetas y más. No hay problema sino entienden todos los detalles, ya que es una mirada rápido sobre un programa completo de *Tensorflow* con los detalles explicados a medida que se avanza.\n",
        "\n",
        "Esta Guia usa [tf.keras](https://www.tensorflow.org/guide/keras), una API de alto nivel para construir y entrenar modelos de redes neuronales en Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL3OqFKZ9dFg"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow y tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Librerias de ayuda\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Importar el set de datos de moda de MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "Esta guia usa el set de datos de [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist)\n",
        "que contiene más de 70000 imágenes en 10 categorias. Las imágenes muestran artículos individuales de ropa a una resolución muy baja (28 por 28 pixeles), tal como se ve aca:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://miro.medium.com/max/1400/1*RkysnlFejHNE4Us5aXmnHQ.jpeg\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "En este lab vamos a usar 60.000 imágenes para entrenar la red neuronal y 10.000 para evaluar que tan exacto aprendió la red a clasificar imágenes de moda. Se puede acceder al dataset Fashion MNIST directamente desde TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "ipFebI_g57Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "Al cargar el dataset, la función retorna cuatro arreglos en `NumPy`:\n",
        "\n",
        "* Los arreglos `train_images` y `train_labels` son los datos del *training set* que se usan para aprender el modelo.\n",
        "* Los arreglos `test_images` y `test_labels` son los datos del *test set* que se usan para probar el modelo.\n",
        "\n",
        "Las imágenes se cargan como arreglos `NumPy` de 28x28, con valores de pixel que varian de 0 a 255 (imagen en escala de grises). Los arreglos *labels* son arreglos de enteros, que van del 0 al 9, con tantas filas como imágenes hay para entrenamiento y para testeo, respectivamente. Estos corresponden a la *clase* de ropa que la imagen representa:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Cada imagen es mapeada a una unica etiqueta. Ya que los nombres de las clases no estan incluídos en los arreglos *labels*, los almacenamos acá para usarlos luego cuando se visualicen las imágenes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Explorar el set de datos\n",
        "\n",
        "Exploramos el la información del dataset antes de entrenar el modelo. Lo siguiente muestra que hay 60.000 imágenes en el set de entrenamiento con cada imagen representada por un arrelgo de 28x28 píxeles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5k_xz1CaWX"
      },
      "source": [
        "train_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIAcvQqMCaWf"
      },
      "source": [
        "Asimismo, hay 60.000 etiquetas en el set de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFYHB2mCaWb"
      },
      "source": [
        "len(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSlYxFuRCaWk"
      },
      "source": [
        "Cada etiqueta es un entero entre 0 y 9:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKnCTHz4CaWg"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMPI88iZpO2T"
      },
      "source": [
        "Hay 10.000 imágenes en el set de pruebas. Otra vez, cada imagen es representada por un arrelgo de 28x28 píxeles:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KFnYlcwCaWl"
      },
      "source": [
        "test_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd0A0Iu0CaWq"
      },
      "source": [
        "Y el set de pruebas contiene 10.000 etiquetas de imagen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJmPr5-ACaWn"
      },
      "source": [
        "len(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Pre-procesar el dataset\n",
        "\n",
        "El set de datos debe ser pre-procesado antes de entrenar la red. Al visualizar la primera imagen en el set de entrenamiento, encontramos que los valores de los pixeles están entre 0 y 255:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4VEw8Ud9Quh"
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(train_images[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz7l27Lz9S1P"
      },
      "source": [
        "Antes de entrenar la red neuronal debemos escalar estos valores en un rango de 0 a 1. Para hacero, dividimos los valores por 255. Es importante que el *training set* y el *testing set* se pre-procesen de la misma forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW5WzIPlCaWv"
      },
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "Para verificar que el set de datos está en el formato adecuado y que están listos para entrenar la red, veamos las primeras 25 imágenes de el *training set* junto al nombre de clase debajo de cada imagen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZTImqg_CaW1"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Construir del Modelo\n",
        "\n",
        "Construir la red neuronal requiere configurar las capas del modelo y luego compilarlo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Configurar las Capas\n",
        "\n",
        "Los bloques de construcción básicos de una red neuronal son las *capas* o *layers*. Las capas extraen representaciones (características o features) del set de datos con el que se alimentan. \n",
        "\n",
        "La mayor parte del *aprendizaje profundo* (deep learning) consiste en encadenar capas simples. La mayoría de las capas tienen parámetros que son aprendidos durante el entrenamiento. En TensorFlow, estas capas son implementadas mediante `tf.keras.layers.Dense`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "La primera capa de esta red, `tf.keras.layers.Flatten`, \n",
        "transforma las imágenes de un arreglo bi-dimensional (de 28x28 píxeles) a un arreglo uni-dimensional (de 28\\*28 píxeles = 784 píxeles). En esta capa no hay parámetros que aprender, solo se *reformatea* el set de datos.\n",
        "\n",
        "Despues de que los píxeles son \"aplanados\", el modelo consiste de una secuencia de dos capas `tf.keras.layers.Dense`. Estas están densamente conectadas, o completamente conectadas. La primera capa `Dense` tiene 128 nodos (o neuronas) con una *función de activación* del tipo *relu*. La segunda (y última) capa es una capa de 10 nodos on una *función de activación* de tipo *softmax*, que devuelve un arreglo de 10 probabilidades que suman 1. Cada nodo contiene una *calificación* que indica la probabilidad de que la imagen actual pertenezca a una de las 10 clases.\n",
        "\n",
        "### Compilar el modelo\n",
        "\n",
        "Antes de que el modelo este listo para ser entrenado, se necesitan algunas configuraciones más. Estas son agregadas durante el paso de compilacion del modelo:\n",
        "\n",
        "* *Loss function*: esto permite medir que tan exacto es el modelo durante el entrenamiento. La idea es minimizar el valor de esta función para \"dirigir\" el modelo en la direccion adecuada.\n",
        "* *Optimizer*: así es como se actualiza el modelo basado en los datos de entrenamiento y su loss function.\n",
        "* *Metrics*: se usan para monitorear los pasos de entrenamiento y de testeo. El siguiente ejemplo usa *accuracy* (exactitud), es decir, la fracción de imágenes que son correctamente clasificadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Entrenar el Modelo\n",
        "\n",
        "Entrenar la red neuronal requiere de los siguientes pasos:\n",
        "\n",
        "1. Entregar los datos de entrenamiento al modelo. En este ejemplo, el set de datos de entrenamiento estan en los arreglos `train_images` y `train_labels`.\n",
        "2. Correr el entreanamiento para que el modelo aprenda a asociar imágenes con etiquetas.\n",
        "3. Pedir al modelo que haga predicciones sobre un set de datos de pruebas, incluido en el arreglo `test_images`. Verificar que las predicciones sean iguales a las etiquetas del arreglo `test_labels`.\n",
        "\n",
        "Para comenzar a entrenar, se llama el método `model.fit`. Se denomina así por que ajusta (*fit*) el modelo a el set de datos de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvwvpA64CaW_"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "A medida que el modelo entrena, la muestran los valores de *loss function* y *accuracy* sobre el **set de datos de entrenamiento**.\n",
        "\n",
        "En este punto vale aclarar terminología de redes neuronales, y que son parámetros del método `fit`:\n",
        "\n",
        "* Un `epoch`: un pase hacia adelante (*forward pass*) y un pase hacia atrás (*backward pass*) de **todos los ejemplos de entrenamiento**.\n",
        "* `batch size`: número de ejemplos de entrenamiento en un forward/backward pass. Cuanto mayor sea el tamaño del lote, más espacio en memoria se necesita.\n",
        "* Número de `iteraciones` = número de pasadas, donde el número de ejemplos de involucrados en cada pasada esta especificado por `[batch size]`. Una pasada es un *forward pass* mas un *backward pass*.\n",
        "\n",
        "Ejemplo: si se tiene 1.000 ejemplos de entrenamiento y el `batch size` es de 500, entonces se necesitan 2 iteraciones para completar 1 `epoch`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Evaluar Accuracy\n",
        "\n",
        "A continuación vamos a estimar el rendimiento del modelo sobre el set de datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VflXLEeECaXC"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "Resulta que la *accuracy* sobre el set de datos de pruebas es un poco menor que la *accuracy* sobre el set de entrenamiento. Esta diferencia entre el entrenamiento y el test se debe al *overfitting* (sobre ajuste). Sobre ajuste sucede cuando un modelo de aprendizaje de maquina (ML) tiene un rendimiento peor sobre un set de datos nuevo (o de testeo), que nunca antes ha visto comparado con el de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## Hacer predicciones\n",
        "\n",
        "Finalmente, con el modelo entrenado ya se pueden hacer predicciones sobre nuevas imágenes. Para esto usamos el método `predict` con las imágenes del conjunto de testeo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "En la celda anterior, el modelo predice la etiqueta para cada imagen en el set de datos de prueba. Miremos la primera prediccion:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "Una prediccion es un arreglo de 10 números (que corresponden a las 10 neuronas de la segunda capa). Estos valores representan el nivel de \"confianza\" (o probabilidad) que el modelo arroja sobre las imágenes de cada uno de los 10 artículos de moda/ropa. Se puede revisar cual tiene el nivel más alto de confianza:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "source": [
        "pred_label = np.argmax(predictions[0])\n",
        "print(pred_label, \" [\", class_names[pred_label], \"]\", sep=\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "De esta manera, el modelo tiene mayor confianza que esta imagen es una \"ankle boot\". Examinando las etiquetas del set de datos de pruebas, podemos ver que esta clasificaion es correcta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Por último vamos crear una función que nos permita graficar la probabilidad de clase de cada una de las imagenes del dataset de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvYmmrpIy6Y1"
      },
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Ov9OFDMmOD"
      },
      "source": [
        "Tomemos como ejemplos la primer imagen del conjunto de testeo (`i=0`) y la décimotercera (`i=12`). Las etiquetas de prediccion correctas estan en azul y las incorrectas estan en rojo. El numero entrega el porcentaje para la etiqueta predicha."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV5jw-5HwSmO"
      },
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko-uzOufSCSe"
      },
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i],  test_labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "Ahora vamos a graficar multiples imágenes con sus predicciones. Notese que el modelo puede estar equivocado aun cuando tiene mucha confianza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQlnbqaw2Qu_"
      },
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R32zteKHCaXT"
      },
      "source": [
        "Finalmente, usamos el modelo entrenado para hacer una predicción sobre una única imagen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRJ7JU7JCaXT"
      },
      "source": [
        "# Grab an image from the test dataset.\n",
        "img = test_images[1]\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz3bVp21CaXV"
      },
      "source": [
        "Los modelos de `tf.keras` se optimizan para hacer predicciones en un lote de ejemplos a la vez. En consecuencia, a pesar de que está utilizando una sola imagen, es necesario añadirla a una lista:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDFh5yF_CaXW"
      },
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "img = (np.expand_dims(img,0))\n",
        "\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "Ahora se puede predecir la etiqueta correcta para esta única imagen:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_rzNSdrCaXY"
      },
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ai-cpLjO-3A"
      },
      "source": [
        "plot_value_array(1, predictions_single[0], test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`model.predict` retorna una lista de listas para cada imagen dentro del lote de imáágenes. Por lo tanto, para tomar la prediccion de la única imagen dentro del lote hacemos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tRmdq_8CaXb"
      },
      "source": [
        "pred_label_single = np.argmax(predictions_single[0])\n",
        "print(pred_label_single, \" [\", class_names[pred_label_single], \"]\", sep=\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFc2HbEVCaXd"
      },
      "source": [
        "Y el modelo predice la etiqueta 2 (pullover)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgiWQh4WPbDL"
      },
      "source": [
        "---\n",
        "\n",
        "# Trabajo Práctico 1 (primera parte)\n",
        "\n",
        "**Acá tienen que dejar los datos de las y los integrantes del grupo:**\n",
        "\n",
        "Nombre y Apellido, DNI, correo eletrónico\n",
        "\n",
        "\n",
        "*   ABDALA AGUSTIN HIPOLITO, 30.968.076, agu007@gmail.com\n",
        "*   ACOSTA LUSA MARTIN EDUARDO, 25.756.515, acostalusamartin@gmail.com\n",
        "*   MENGUAL MATIAS, 37.089.323, mengualmatias@gmail.com\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j3DS0bPOXJd"
      },
      "source": [
        "## **EJERCICIO 1.1**: predecir nuevas imágenes de moda con el modelo previamente entrenado\n",
        "\n",
        "1. **Crear un nuevo dataset** propio con **30 imágenes** en total (3 imágenes de cada categoría). Estás imágenes no deben ser tomadas del dataset original (Fashion MNIST). Pueden capturar sus propias imágenes o buscarlas en la web. **Como sea, recuerden que deben preprocesar las imágenes para que tengan exactamente el mismo formato de entrada que requiere la red.**\n",
        "\n",
        "1. **Mostrar todas las imágenes del conjunto de testeo** creado por ustedes para que se pueda inspeccionar rápidamente su contenido.\n",
        "\n",
        "1. Tomando la ANN previamente entrenada, **predecir las etiquetas** de cada imagen del dataset y reportar los resultados de **accuracy** (y **opcionalmente** cualquier otra métrica que le resulte adecuada, como ser **precisión** y **recall**)\n",
        "\n",
        "TIP: reutilice las celdas de código presentadas anteriormente\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Creación de un nuevo dataset\n",
        "El mismo contiene 30 imagenes (3 de cada categoria) buscadas al azar en la web. El formato de las imagenes es JPG y se ingesta desde un archivo comprimido (ZIP) previamente subido a GitHub"
      ],
      "metadata": {
        "id": "kgEXewrs34DG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Ingesta de imagenes"
      ],
      "metadata": {
        "id": "lQarliUQ40so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Files\n",
        "!wget https://github.com/agustinabdala/diplodatos/blob/main/06_COMPUTER_VISION/INPUT_FILES/Vision%20por%20Computadora_jpeg.zip?raw=true -O /content/fashion_file.zip\n",
        "!unzip -o /content/fashion_file.zip -d /content/images/"
      ],
      "metadata": {
        "id": "Jk1XSIelpcC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR0kdgZLV73x"
      },
      "source": [
        "#importing the libraries\n",
        "import os \n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#setting the path to the directory containing the pics\n",
        "path = '/content/images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuacion se acondicionan las imagenes ingestada entre otras cosas se la lleva a escala de grises y se la transforma a una imagen de 28x28 píxeles"
      ],
      "metadata": {
        "id": "ZYB5n2FJ5OLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#appending the pics to the training data list\n",
        "downloadad_images = []\n",
        "for img in os.listdir(path):\n",
        "    try:\n",
        "      pic = cv2.imread(os.path.join(path,img))\n",
        "      pic = cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY)\n",
        "      pic = cv2.resize(pic,(28,28))\n",
        "      pic = cv2.bitwise_not(pic)\n",
        "      downloadad_images.append([pic])\n",
        "    except: continue\n",
        "\n",
        "#converting the list to numpy array and saving it to a file using #numpy.save\n",
        "np.save(os.path.join(path,'features'),np.array(downloadad_images))\n",
        "#loading the saved file once again\n",
        "saved = np.load(os.path.join(path,'features.npy'))"
      ],
      "metadata": {
        "id": "195BUUjfcQx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved = np.squeeze(saved, axis=None)"
      ],
      "metadata": {
        "id": "KM64iOc0h6Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualización de la cuarta imagen cargada"
      ],
      "metadata": {
        "id": "DAge9miy4-Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(saved[3])"
      ],
      "metadata": {
        "id": "WSPSKvLweCbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Muestra de todas las imágenes del conjunto de testeo creado para inspeccionar rápidamente su contenido."
      ],
      "metadata": {
        "id": "mvVcO9c38ZaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualización de las 30 imagenes cargadas"
      ],
      "metadata": {
        "id": "UcM4Swwo6YeX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga de etiquetas de la imagenes"
      ],
      "metadata": {
        "id": "rjl5XlYN6yaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#labels_saved = ['Dress', 'Trouser','Pullover' , 'Coat' ,'Trouser', 'Ankle' 'boot','Pullover','Shirt','Ankle boot','Sneaker','Sneaker','Dress','Coat','Coat','Bag','Sneaker','Dress','T-shirt/top','T-shirt/top','Trouser','Shirt','Ankle boot','T-shirt/top','Sandal','Pullover','Shirt','Bag','Sandal','Sandal','Bag']\n",
        "labels_saved_num = np.array([2,9,6,2,2,4,5,1,6,7,3,8,5,4,0,8,4,6,3,7,9,1,5,7,9,8,1,0,3,0])\n"
      ],
      "metadata": {
        "id": "ARN4BZVP0xxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(30):\n",
        "    plt.subplot(6,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(saved[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[labels_saved_num[i]])\n",
        "    \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mS0MMDaLe_85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Predicción de las etiquetas de cada imagen del dataset, tomando la ANN previamente entrenada y reporte delos resultados de accuracy "
      ],
      "metadata": {
        "id": "v5d4D1yubc7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividiendo por 255 escalamos los datos entre 0 y 1"
      ],
      "metadata": {
        "id": "kdOoI3LB6lss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved = saved / 255.0"
      ],
      "metadata": {
        "id": "Nqg4Vd_3eww2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(saved)\n",
        "predictions.shape, saved.shape"
      ],
      "metadata": {
        "id": "a_vCIayFfS3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicción utilizando el modelo previamente entrenado"
      ],
      "metadata": {
        "id": "I8IOICb0jltp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first X test images, their predicted labels, and the true labels.\n",
        "# Color correct predictions in blue and incorrect predictions in red.\n",
        "num_rows = 6\n",
        "num_cols = 5\n",
        "num_images = num_rows*num_cols\n",
        "\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i],labels_saved_num, saved)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions[i], labels_saved_num)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-SqelpJVUxHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array_saved = np.array(labels_saved_num)\n",
        "test_loss, test_acc = model.evaluate(saved,  array_saved, verbose=2)\n",
        "\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "AGlfouscv4yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede ver la presición del modelo ha bajado respecto al test set original (Fashion MNIST), se estima que esto se debe a que las imagenes no son tomadas de la misma forma (posición, cantidad, fondo). Por ejemplo en las imagenes del dataset original los calzados son mostrados de perfil y por unidad, mientas que en las imagenes cargdas se tiene calzado en cualquiier posición y por pares"
      ],
      "metadata": {
        "id": "lSR0MnyNcq48"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMv1VZqcUWGQ"
      },
      "source": [
        "## **EJERCICIO 1.2 (OPCIONAL)**: entrenar la red para resolver un nuevo problema\n",
        "\n",
        "Realice una búsqueda en internet para relevar dataset similares al propuesto en este lab. Elija un dataset arbitario y con este vuelva a realizar el proceso de completo para entrenar una ANN como clasificador de imágenes sobre el nuevo dateset\n",
        "\n",
        "TIP: dejo dos links para facilitar la búsqueda\n",
        "- https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research\n",
        "- https://en.wikipedia.org/wiki/Caltech_101\n"
      ]
    }
  ]
}
